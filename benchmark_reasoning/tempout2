Answer Extractor - LLM-Based Answer Extraction
==================================================
Using extraction model: openai/phi-4-reasoning-plus-mlx
Auto-discovered latest benchmark results: JSON_RESULTS/benchmark_results_openai_qwen3-next-80b-a3b-instruct_20250915_175502.json
Processing benchmark results from: JSON_RESULTS/benchmark_results_openai_qwen3-next-80b-a3b-instruct_20250915_175502.json
Original results:
  Total problems: 22
  Original accuracy: 59.1%
  Datasets: ['gsm8k', 'winogrande', 'piqa', 'hellaswag', 'logiqa', 'competition_math', 'aime_2024'] ({'gsm8k': 5, 'winogrande': 3, 'piqa': 3, 'hellaswag': 3, 'logiqa': 2, 'competition_math': 5, 'aime_2024': 1})

Processing gsm8k...
  Problem 1/5
  Problem 2/5
  Problem 3/5
  Problem 4/5
  Problem 5/5
  gsm8k Results:
    Original accuracy: 80.0%
    LLM accuracy: 80.0%
    Successful extractions: 5/5

Processing winogrande...
  Problem 1/3
  Problem 2/3
  Problem 3/3
  winogrande Results:
    Original accuracy: 66.7%
    LLM accuracy: 66.7%
    Successful extractions: 3/3

Processing piqa...
  Problem 1/3
  Problem 2/3
  Problem 3/3
  piqa Results:
    Original accuracy: 66.7%
    LLM accuracy: 100.0%
    Successful extractions: 3/3

Processing hellaswag...
  Problem 1/3
  Problem 2/3
  Problem 3/3
  hellaswag Results:
    Original accuracy: 100.0%
    LLM accuracy: 100.0%
    Successful extractions: 3/3

Processing logiqa...
  Problem 1/2
  Problem 2/2
  logiqa Results:
    Original accuracy: 50.0%
    LLM accuracy: 100.0%
    Successful extractions: 2/2

Processing competition_math...
  Problem 1/5
  Problem 2/5
  Problem 3/5
  Problem 4/5
  Problem 5/5
  competition_math Results:
    Original accuracy: 0.0%
    LLM accuracy: 0.0%
    Successful extractions: 5/5

Processing aime_2024...
  Problem 1/1
  aime_2024 Results:
    Original accuracy: 100.0%
    LLM accuracy: 100.0%
    Successful extractions: 1/1

============================================================
EXTRACTION COMPARISON SUMMARY
============================================================
Original benchmark accuracy: 59.1%
Extraction success rate: 100.0%
Average extraction confidence: 0.95
Low confidence extractions: 0/22 (0.0%)

Dataset Comparison:
Dataset              Original   LLM        Improved   Degraded  
------------------------------------------------------------
gsm8k                80.0%     80.0%     0         0        
winogrande           66.7%     66.7%     0         0        
piqa                 66.7%     100.0%    1         0        
hellaswag            100.0%    100.0%    0         0        
logiqa               50.0%     100.0%    1         0        
competition_math     0.0%      0.0%      0         0        
aime_2024            100.0%    100.0%    0         0        
------------------------------------------------------------
OVERALL              59.1%     68.2%    

Net improvement: +9.1%

Enhanced results saved to: JSON_RESULTS/benchmark_results_openai_qwen3-next-80b-a3b-instruct_20250915_175502_llm_extracted.json
